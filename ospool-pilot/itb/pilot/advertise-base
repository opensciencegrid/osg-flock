#!/bin/bash
#
# This script probes a system for properties useful for OSGVO and
# friends. This particular script runs "outside" Singularity.
#
# To be able to support both
# integration with GlideinWMS and HTCondor startd cron, argv1 is used
# to determine what mode we are in. If argv1 points to a glidein_config
# file, GlideinWMS mode is assumed. If argv1 is "NONE", HTCondor startd
# cron mode is assumed.
#
# More information:
#    http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.prd/factory/custom_scripts.html
#    http://research.cs.wisc.edu/htcondor/manual/v8.2/4_4Hooks.html
#
# Example HTCondor startd cron entry:
#
# STARTD_CRON_JOBLIST = $(STARTD_CRON_JOBLIST) osgvo
# STARTD_CRON_osgvo_EXECUTABLE = /opt/osgvo/osgvo-node-advertise
# STARTD_CRON_osgvo_PERIOD = 30m
# STARTD_CRON_osgvo_MODE = periodic
# STARTD_CRON_osgvo_RECONFIG = true
# STARTD_CRON_osgvo_KILL = true
# STARTD_CRON_osgvo_ARGS = NONE

#######################################################################
#
# Configuration
#

# OSG_GLIDEIN_VERSION is an ever-increasing version of the glideins.
# This can be used by negotiators or users, for example to match
# against a glidein newer than some base with new features.
OSG_GLIDEIN_VERSION=791
#######################################################################


glidein_config="$1"

function info {
    echo "INFO  " "$@" 1>&2
}

function my_warn {
    echo "WARN  " "$@" 1>&2
    export GLIDEIN_VALIDATION_WARNINGS="$*. $GLIDEIN_VALIDATION_WARNINGS"
}

function advertise {
    # atype is the type of the value as defined by GlideinWMS:
    #   I - integer
    #   S - quoted string
    #   C - unquoted string (i.e. Condor keyword or expression)
    key="$1"
    value="$2"
    atype="$3"

    if [ "$glidein_config" != "NONE" ]; then
        add_config_line_safe $key "$value"
        add_condor_vars_line $key "$atype" "-" "+" "Y" "Y" "-"
    fi

    if [ "$atype" = "S" ]; then
        echo "$key = \"$value\""
    else
        echo "$key = $value"
    fi
}

function get_glidein_config_value {
    # extracts a config attribute value from 
    # $1 is the attribute key
    CF=$glidein_config
    if [ "$glidein_config" = "NONE" ]; then
        CF="$PWD/glidein_config"
    fi
    KEY="$1"
    VALUE=`(cat $CF | grep "^$KEY " | tail -n 1 | sed "s/^$KEY //") 2>/dev/null`
    echo "$VALUE"
}



###########################################################
# Ensure only one copy of this script is running at the 
# same time. For example, if a mount or something hangs
# further down, we do not want more copies of this script
# to add to the problem.

export PID_FILE=osgvo-node-advertise.pid
if [ -e $PID_FILE ]; then
    OLD_PID=`cat $PID_FILE 2>/dev/null`
    if kill -0 $OLD_PID >/dev/null 2>&1; then
        exit 0
    fi
fi
echo $$ >$PID_FILE

#############################################################################
# At least glideinWMS 3.7.5 depends on the existence of a file named
# log/StarterLog.  However, starting in 8.9.13, this log file no longer is
# created by HTCondor.  To fix the statistics reporting, we simply create it
# here.
mkdir -p log execute
touch log/StarterLog

###########################################################
# We have two env variables which can be added to in this
# script to provide an expression for the START expression
# and a general warnings string which gets published in the
# ad. These are env variables until the end.

export GLIDEIN_VALIDATION_EXPR="True"
export GLIDEIN_VALIDATION_WARNINGS=""

info "This is a setup script for the OSPool frontend."
info "In case of problems, contact Mats Rynge (rynge@isi.edu)"
info "Running in directory $PWD"
    
if [ -e glidein_config ]; then
    # gwms 
    info "GWMS directory detected. Staying in $PWD"
elif [ -e ../glidein_config ]; then
    # gwms stupid tmp dir for periodic scripts - this breaks
    # out ability to cache results
    cd ../
    info "GWMS tmp directory detected. Switched directory to $PWD"
elif [ "x$LOCAL_DIR" != "x" ]; then
    # osgvo-docker-pilot - use specified dir
    cd $LOCAL_DIR
    info "osgvo-docker-pilot \$LOCAL_DIR directory detected. Switched directory to $PWD"
else
    # find a good directory for our tests - we need something that we
    # can re-enter later to pick up cached results
    for DER in $GLIDEIN_Tmp_Dir $TMP $TMPDIR /tmp . ; do
        # do we have write permissions
        if touch $DER/.writetest.$$ >/dev/null 2>&1; then
            rm -f $DER/.writetest.$$
            if mkdir -p $DER/osgvo-node-advertise.work >/dev/null 2>&1; then
                cp $0 $DER/osgvo-node-advertise.work/
                if [ -e add_config_line.source ]; then
                    cp add_config_line.source $DER/osgvo-node-advertise.work/
                fi
                cd $DER/osgvo-node-advertise.work
                info "Switched working directory to $PWD"
                break
            fi
        fi
    done
fi

# bash can set a default PATH - make sure it is exported
export PATH=$PATH

# some sites do not have PATH set
if [ "x$PATH" = "x" ]; then
    export PATH="/usr/local/bin:/usr/bin:/bin"
    my_warn "PATH is empty, setting it to $PATH"
fi
info "PATH is set to $PATH"

#############################################################################
#
# Some tests are too heavy-weight to run every
# 5 minutes. Such test can drop a file named $TEST_FILE_1H.NNNNNNN
# in cwd. These files will be cleaned up after 60 minutes and allow the
# test to rerun then again. There is also a 4 hour version.
#

TEST_FILE_1H=osgvo.test-results.1h
TEST_FILE_4H=osgvo.test-results.4h

# clean up old ones
find . -maxdepth 1 -name $TEST_FILE_1H.\* -mmin +60 -exec rm {} \;
find . -maxdepth 1 -name $TEST_FILE_4H.\* -mmin +240 -exec rm {} \;
find . -maxdepth 1 -name adv-singularity-work.\* -mmin +240 -exec rm -rf {} \;

# CVMFS_BASE defaults to /cvmfs but can be overridden in case of for example cvmfsexec
if [ "x$CVMFS_BASE" = "x" ]; then
    CVMFS_BASE="/cvmfs"
fi

if [ "x$glidein_config" = "x" ]; then
    glidein_config="NONE"
    info "No arguments provided - assuming HTCondor startd cron mode"
else
    info "Arguments to the script: $*"
    if [ -e "$glidein_config.saved" ]; then
        info "$glidein_config.saved found; not doing any more writes"
        glidein_config="NONE"
    fi
fi

if [ "$glidein_config" != "NONE" ]; then
    ###########################################################
    # import advertise and add_condor_vars_line functions
    if [ "x$add_config_line_source" = "x" ]; then
        export add_config_line_source=`grep '^ADD_CONFIG_LINE_SOURCE ' $glidein_config | awk '{print $2}'`
        export condor_vars_file=`grep -i "^CONDOR_VARS_FILE " $glidein_config | awk '{print $2}'`
    fi

    # full path is problematic as sometimes we are inside a container - however, looks like
    # the file is always named "add_config_line.source", so use that
    add_config_line_source=$PWD/add_config_line.source

    info "Sourcing $add_config_line_source"
    source $add_config_line_source
fi

# timeout, if available, is used across many tests
TIMEOUT=$(which timeout 2>/dev/null)
if [ "x$TIMEOUT" != "x" ]; then
    TIMEOUT="$TIMEOUT -k 30s 30s"
fi

advertise OSG_GLIDEIN_VERSION $OSG_GLIDEIN_VERSION "I"

# OSPool - this attribute should _only_ be set to True if
# the EP is registering to the production OSPool CMs, and
# it is a generally availalbe EP for fairshare (that is,
# no project or other START restrictions)
GLIDEIN_Collector=$(get_glidein_config_value GLIDEIN_Collector)
GLIDECLIENT_Group=$(get_glidein_config_value GLIDECLIENT_Group)
GLIDEIN_Start_Extra=$(get_glidein_config_value GLIDEIN_Start_Extra)
OSG_PROJECT_NAME=$(get_glidein_config_value OSG_PROJECT_NAME)
OSPool="False"
if (echo "$GLIDEIN_Collector" | grep cm-1.ospool.osg-htc.org) >/dev/null 2>&1; then
    if (echo "$GLIDECLIENT_Group" | grep -E '^(gpu|main|main-canary)$') >/dev/null 2>&1; then
        # gwms - use the group as determining factor
        OSPool="True"
    elif [ "x$GLIDECLIENT_Group" = "xmain-container" ]; then
        # Container - need to check if there are extra start expressions
        # We have to check this HTCondor expression without fully evaluating it
        # For now, check if the expression contains owner/project as such
        # attributes could be used to limit the pilot
        EXTRA_CLEAN=$(echo "$GLIDEIN_Start_Extra" | grep -E -i 'owner|project')
        if [ "x$EXTRA_CLEAN" = "x" -a "x$OSG_PROJECT_NAME" = "x" ]; then
            OSPool="True"
        fi
    fi
fi
advertise OSPool "$OSPool" "C"

# we need the "outside" kernel version to be able to steer
# singularity jobs to kernel/glibcs which are not too old
VER=`uname -r | sed 's/-.*//'`
MAJ=`echo $VER | sed -E 's/([0-9]+)\.([0-9]+)\.([0-9]+)/\1/'`
MIN=`echo $VER | sed -E 's/([0-9]+)\.([0-9]+)\.([0-9]+)/\2/'`
PATCH=`echo $VER | sed -E 's/([0-9]+)\.([0-9]+)\.([0-9]+)/\3/'`
VER=$(( 10000 * $MAJ + 100 * $MIN + $PATCH ))
if [ "x$VER" != "x" ]; then
    if [ $VER -gt 10000 ]; then
        advertise OSG_HOST_KERNEL_VERSION "$VER" "I"
    fi
fi

# firewall testing - check a set of common ports our projects need
for PORT in 80 1094 2880 8000 8443 27017; do
    if [ -e $TEST_FILE_4H.port.$PORT ]; then
        OUT=$(cat $TEST_FILE_4H.port.$PORT)
    else
        OUT="False"
        if curl --fail --silent --retry 0 --max-time 15 -o /dev/null http://ospool-network-test.osg.chtc.io:$PORT; then
            OUT="True"
        fi
        echo $OUT >$TEST_FILE_4H.port.$PORT
    fi
    advertise PORT_$PORT "$OUT" "C"
done

# verify http_proxy/OSG_SQUID_LOCATION
PROXY_CHECKS=0
PROXY_LOCATION=""
if [ -e $TEST_FILE_4H.http_proxy.checks ]; then
    PROXY_CHECKS=$(cat $TEST_FILE_4H.http_proxy.checks)
    PROXY_LOCATION=$(cat $TEST_FILE_4H.http_proxy.location)
else
    CURL=$(curl --version 2>/dev/null)
    for PROXY_CANDIDATE in $http_proxy $OSG_SQUID_LOCATION; do
        PROXY_CHECKS=$(($PROXY_CHECKS + 1))
        if [ "x$CURL" != "x" ]; then
            env http_proxy=$PROXY_CANDIDATE curl -s -m 10 -o /dev/null http://cm-1.ospool.osg-htc.org/overview/
        else
            env http_proxy=$PROXY_CANDIDATE wget -q --timeout 10 -O /dev/null http://cm-1.ospool.osg-htc.org/overview/
        fi
        if [ $? = 0 ]; then
            PROXY_LOCATION="$PROXY_CANDIDATE"
            break
        fi
    done
    echo $PROXY_CHECKS >$TEST_FILE_4H.http_proxy.checks
    echo $PROXY_LOCATION >$TEST_FILE_4H.http_proxy.location
fi

if [ "x$PROXY_LOCATION" = "x" -a $PROXY_CHECKS -gt 0 ]; then
    # checks peformed, but failed - limit what file transfers we can do
    advertise HasFileTransferPluginMethods "data,ftp,file" "S"
fi
if [ "x$PROXY_LOCATION" != "x" ]; then
    advertise "http_proxy" "$PROXY_LOCATION" "S"
fi

# some images require unsquashfs
HAS_unsquashfs="False"
if unsquashfs -v >/dev/null 2>&1; then
    HAS_unsquashfs="True"
fi
# singularity also looks in places which may not be in user PATH
if [ -e /usr/sbin/unsquashfs ]; then
    HAS_unsquashfs="True"
fi
advertise HAS_unsquashfs "$HAS_unsquashfs" "C"

# check for locally cached .sif images - this will be helpful when determining 
# we want to disable Singularity if CVMFS is not available
# while we're at it, advertise the size
GWMS_SINGULARITY_CACHED_IMAGES=$( (cd images/ && ls *.sif | sort | paste -d, -s) 2>/dev/null)
if [[ "x$GWMS_SINGULARITY_CACHED_IMAGES" != "x" ]]; then
    advertise GWMS_SINGULARITY_CACHED_IMAGES "$GWMS_SINGULARITY_CACHED_IMAGES" "S"
fi
GWMS_SINGULARITY_CACHED_IMAGES_KB=$( (du --apparent-size -kc images/*.sif | tail -n 1 | awk '{print $1}') 2>/dev/null)
if [[ "x$GWMS_SINGULARITY_CACHED_IMAGES_KB" != "x" ]]; then
    advertise GWMS_SINGULARITY_CACHED_IMAGES_KB "$GWMS_SINGULARITY_CACHED_IMAGES_KB" "I"
fi


function disk_is_full {
    local dir_to_check="$1"
    local required_space_gb="$2"
    # some sites have tiny envs which could affect this test
    # for example, undefined $HOME
    if [ -z "$dir_to_check" ]; then
        return 1
    fi
    # also ignore directories which do not exist
    if [ ! -e "$dir_to_check" ]; then
        return 1
    fi
    (( disk_free=$(df -kP "$dir_to_check" 2>/dev/null | awk '{if (NR==2) print $4}') ))
    [[ $(( disk_free / 1024 / 1024 )) -lt $required_space_gb ]]
}

# check space in SINGULARITY_CACHEDIR and SINGULARITY_TMPDIR
#
cachedir_required_space_gb=5
tmpdir_required_space_gb=5

# ~/.singularity/cache might not have been created yet; if so, check its parents for disk space
cachedir_to_check=${SINGULARITY_CACHEDIR:-$HOME/.singularity/cache}
[[ -e $cachedir_to_check ]] || cachedir_to_check=$HOME/.singularity
[[ -e $cachedir_to_check ]] || cachedir_to_check=$HOME
tmpdir_to_check=${SINGULARITY_TMPDIR:-${TMPDIR:-/tmp}}

if disk_is_full "$cachedir_to_check" "$cachedir_required_space_gb" || \
    disk_is_full "$tmpdir_to_check" "$tmpdir_required_space_gb"
then
    advertise SINGULARITY_DISK_IS_FULL "True" C
else
    advertise SINGULARITY_DISK_IS_FULL "False" C
fi

# advertise some monitoring data
advertise MONITORING_NO_FILES $(find . -type f | wc -l) "I"
advertise MONITORING_DISK_USAGE $(du -s . | awk '{print $1;}') "I"

##################
# cvmfs filesystem availability
GLIDEIN_Entry_Name=$(get_glidein_config_value GLIDEIN_Entry_Name)
info "Checking for CVMFS availability and attributes..."
for FS in \
   ams.cern.ch \
   atlas.cern.ch \
   belle.cern.ch \
   clicdp.cern.ch \
   cms.cern.ch \
   connect.opensciencegrid.org \
   eic.opensciencegrid.org \
   gluex.osgstorage.org \
   gwosc.osgstorage.org \
   icecube.opensciencegrid.org \
   icecube.osgstorage.org \
   larsoft-ib.opensciencegrid.org \
   larsoft.opensciencegrid.org \
   ligo.storage.igwn.org \
   nexo.opensciencegrid.org \
   oasis.opensciencegrid.org \
   public-uc.osgstorage.org \
   sft.cern.ch \
   singularity.opensciencegrid.org \
   shared.storage.igwn.org \
   snoplus.egi.eu \
   software.igwn.org \
   sphenix.opensciencegrid.org \
   spt.opensciencegrid.org \
   stash.osgstorage.org \
   sw.lsst.eu \
   unpacked.cern.ch \
   veritas.opensciencegrid.org \
   virgo.storage.igwn.org \
   xenon.opensciencegrid.org \
; do
    FS_CONV=`echo "$FS" | sed 's/[\.-]/_/g'`
    FS_ATTR="HAS_CVMFS_$FS_CONV"
    RESULT="False"
    
    if [ -e $TEST_FILE_4H.cvmfs-disabled.$FS ]; then
        advertise $FS_ATTR "False" "C"
        if [ "x$FS" = "xsingularity.opensciencegrid.org" -a "x$GWMS_SINGULARITY_CACHED_IMAGES" = "x" ]; then
            advertise HAS_SINGULARITY "False" "C"
            advertise SINGULARITY_COMMENT "Disabled due to CVMFS availability/errors" "S"
        fi
        continue
    fi

    if ($TIMEOUT ls -l "$CVMFS_BASE"/$FS/. >/dev/null 2>&1); then
        RESULT="True"

        # add the revision 
        REV_ATTR="CVMFS_${FS_CONV}_REVISION"
        REV_VAL=$($TIMEOUT /usr/bin/attr -q -g revision "$CVMFS_BASE"/$FS/. 2>/dev/null)
        # some site mount /cvmfs over NFS and attr will not work
        if [ "x$REV_VAL" = "x" ]; then
            REV_VAL=0
        fi

        # add the error count
        NIOERR_ATTR="CVMFS_${FS_CONV}_NIOERR"
        NIOERR_VAL=$($TIMEOUT /usr/bin/attr -q -g nioerr "$CVMFS_BASE"/$FS/. 2>/dev/null)
        # some site mount /cvmfs over NFS and attr will not work
        if [ "x$NIOERR_VAL" = "x" ]; then
            NIOERR_VAL=-1
        fi
        
        # last ioerr
        LAST_IOERR_ATTR="CVMFS_${FS_CONV}_LAST_IOERR"
        LAST_IOERR_VAL=$($TIMEOUT /usr/bin/attr -q -g timestamp_last_ioerr "$CVMFS_BASE"/$FS/. 2>/dev/null)
        # some site mount /cvmfs over NFS and attr will not work
        if [ "x$LAST_IOERR_VAL" = "x" -o "x$LAST_IOERR_VAL" = "x0" ]; then
            LAST_IOERR_VAL=-1
        else
            # convert ts to seconds since
            NOW=$(date +'%s')
            LAST_IOERR_VAL=$(($NOW - $LAST_IOERR_VAL))
        fi

        # disable if the mount has had recent errors
        if [ $LAST_IOERR_VAL -ge 0 -a $LAST_IOERR_VAL -lt 14400 ]; then
            RESULT="False"
        fi
       
        # UUTAH is special case - broken NFS
        if (echo "$GLIDEIN_Entry_Name" | egrep -i "UUTAH") >/dev/null 2>&1; then
            RESULT="False"
        fi
        
        # disable singularity if the singularity cvmfs has errors
        if [ "x$FS" = "xsingularity.opensciencegrid.org" -a "x$GWMS_SINGULARITY_CACHED_IMAGES" = "x" ]; then
            if [ $RESULT = "False" ]; then
                advertise HAS_SINGULARITY "False" "C"
                advertise SINGULARITY_COMMENT "Disabled due to CVMFS availability/errors" "S"
            fi
        fi

        # now we are ready to advertise
        advertise $FS_ATTR "$RESULT" "C"
        advertise $REV_ATTR "$REV_VAL" "I"
        advertise $NIOERR_ATTR "$NIOERR_VAL" "I"
        advertise $LAST_IOERR_ATTR "$LAST_IOERR_VAL" "I"

        # remember failures - we do not want to run on cvmfs if it comes and goes...
        if [ $RESULT = "False" ]; then
            touch $TEST_FILE_4H.cvmfs-disabled.$FS
        fi
    else
        # $FS is not available
        advertise $FS_ATTR "False" "C"
        # remember failures - we want do not want to run on cvmfs if it comes and goes...
        if [ $RESULT = "False" ]; then
            touch $TEST_FILE_4H.cvmfs-disabled.$FS
        fi
    fi

done

# update timestamp?
TS_ATTR="CVMFS_oasis_opensciencegrid_org_TIMESTAMP"
TS_VAL=`(cat "$CVMFS_BASE"/oasis.opensciencegrid.org/osg/update.details  | egrep '^Update unix time:' | sed 's/.*: //') 2>/dev/null`
if [ "x$TS_VAL" != "x" ]; then
    # make sure it is an integer
    if [ "$TS_VAL" -eq "$TS_VAL" ] 2>/dev/null; then
        advertise $TS_ATTR "$TS_VAL" "I"
    fi
fi

###########################################################
# system attributes from the host

VIRTUALIZATION=`(systemd-detect-virt) 2>/dev/null`
if [ "x$VIRTUALIZATION" != "x" ]; then
    advertise VIRTUALIZATION_TECHNOLOGY "$VIRTUALIZATION" "S"
fi

SHM_AVAILABLE=`(df /dev/shm --output=size --block-size=1k | tail -n 1) 2>/dev/null`
if [ "x$SHM_AVAILABLE" != "x" ]; then
    advertise SHM_AVAILABLE "$SHM_AVAILABLE" "I"
fi


##################
# stashcp

# this is now handled in additional-htcondor-config - just advertise
# some old attributes for backward compatibility
advertise OSDF_VERIFIED "OSDF_PLUGIN_VERSION =!= UNDEFINED" "C"
advertise STASHCP_VERIFIED "OSDF_PLUGIN_VERSION =!= UNDEFINED" "C"

###########################################################
# Project restriction
if [[ -n $OSG_PROJECT_NAME ]]; then
    info "OSG_PROJECT_NAME=$OSG_PROJECT_NAME"
    advertise OSG_PROJECT_NAME "$OSG_PROJECT_NAME" "S"
    advertise OSG_PROJECT_RESTRICTION "ProjectName =?= OSG_PROJECT_NAME" "C"
else
    info "OSG_PROJECT_NAME is unset"
fi

##################
# mostly done - update START validation expressions and warnings attribute
if [ -e stop-glidein.stamp -o -e ../stop-glidein.stamp ]; then
    advertise OSG_NODE_VALIDATED "False" "C"
    advertise OSG_NODE_WARNINGS "Node is shutting down due to stop-glidein file" "S"
else
    advertise OSG_NODE_VALIDATED "$GLIDEIN_VALIDATION_EXPR" "C"
    if [ "x$GLIDEIN_VALIDATION_WARNINGS" != "x" ]; then
        advertise OSG_NODE_WARNINGS "$GLIDEIN_VALIDATION_WARNINGS" "S"
    fi
fi

##################

# Save a backup copy of glidein_config that won't get clobbered by startd_crons; also use this as a sentinel
# so subsequent runs of this script won't modify glidein_config if it exists.
if [[ $glidein_config != "NONE" && ! -e "$glidein_config.saved" ]]; then
    cp -p "$glidein_config" "$glidein_config.saved"
fi

# send extra monitoring information regularly
if [ ! -e $TEST_FILE_1H.panopticon ]; then
    URL="https://osg.k.scitech.group/ospool-panopticon/static/ospool-panopticon"
    (curl -s -m 20 -o ospool-panopticon $URL || wget -q --timeout 20 -O ospool-panopticon $URL) >/dev/null 2>&1
    if [ -e ospool-panopticon ]; then
        chmod +x ospool-panopticon
        ./ospool-panopticon >/dev/null 2>&1
    fi
    touch $TEST_FILE_1H.panopticon
fi

# Advertise this env var if present
if [[ -n $OSG_INSTITUTION_ID ]]; then
    advertise OSG_INSTITUTION_ID "$OSG_INSTITUTION_ID" "S"
fi


rm -f $PID_FILE
info "All done - time to do some real work!"

