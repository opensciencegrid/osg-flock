#!/bin/bash

glidein_config="$1"

function info {
    echo "INFO  " $@ 1>&2
}

function warn {
    echo "WARN  " $@ 1>&2
}


###########################################################
# import add_config_line and add_condor_vars_line functions

add_config_line_source=`grep '^ADD_CONFIG_LINE_SOURCE ' $glidein_config | awk '{print $2}'`
source $add_config_line_source

# Patch over add_config_line() with a safer version
# This will be fixed in gWMS 3.9.6
add_config_line() {
    # Ignore the call if the exact config line is already in there
    if ! grep -q "^${*}$" "${glidein_config}"; then
        # Use temporary files to make sure multiple add_config_line() calls don't clobber
        # the glidein_config.
        local r="$(head -c16 /dev/urandom | base64 -w0 - | tr / _)"
        local tmp_config1="${glidein_config}.$r.1"
        local tmp_config2="${glidein_config}.$r.2"

        # Copy the glidein config so it doesn't get modified while we grep out the old value
        if ! cp -p "${glidein_config}" "${tmp_config1}"; then
            warn "Error writing ${tmp_config1}"
            rm -f "${tmp_config1}"
            exit 1
        fi
        grep -v "^$1 " "${tmp_config1}" > "${tmp_config2}"
        rm -f "${tmp_config1}"
        if [ ! -f "${tmp_config2}" ]; then
            warn "Error creating ${tmp_config2}"
            exit 1
        fi
        # NOTE that parameters are flattened if not quoted, if there are blanks they are separated by single space
        echo "$@" >> "${tmp_config2}"

        # Replace glidein config atomically
        if ! mv -f "${tmp_config2}" "${glidein_config}"; then
            warn "Error updating ${glidein_config} from ${tmp_config2}"
            rm -f "${tmp_config2}"
            exit 1
        fi
    fi
}
# End add_config_line() patch

condor_vars_file=`grep -i "^CONDOR_VARS_FILE " $glidein_config | awk '{print $2}'`

###########################################################
# enable job duration and busy stats
add_config_line STATISTICS_TO_PUBLISH_LIST "JobDuration, JobBusyTime"
add_condor_vars_line STATISTICS_TO_PUBLISH_LIST "C" "-" "+" "N" "N" "-"

# black holes, oh my (https://opensciencegrid.atlassian.net/browse/OSPOOL-3)
add_config_line IsBlackHole "IfThenElse(RecentJobDurationAvg is undefined, false, RecentJobDurationCount >= 10 && RecentJobDurationAvg < 180)"
add_condor_vars_line IsBlackHole "C" "-" "+" "N" "Y" "-"

# excessive load, probably due to swapping (https://opensciencegrid.atlassian.net/browse/OSPOOL-2)
add_config_line HasExcessiveLoad "LoadAvg > 2*DetectedCpus + 2"
add_condor_vars_line HasExcessiveLoad "C" "-" "+" "N" "Y" "-"

# out of disk space (https://opensciencegrid.atlassian.net/browse/OSPOOL-4)
# note: Unlike DISK, RESERVED_DISK is in megabytes.
# As of July 2022, the HTCondor manual incorrectly states this is in kilobytes.
# This change was verified by examining the code.
add_config_line RESERVED_DISK "3000"
add_condor_vars_line RESERVED_DISK "C" "-" "+" "N" "N" "-"

# use df and allocated cores to determine disk allocation (https://opensciencegrid.atlassian.net/browse/OSPOOL-5)
# but only if we think we are not "whole node"
allocated_cpus=$(grep -i "^GLIDEIN_CPUS " "$glidein_config" | cut -d ' ' -f 2-)
total_cpus=$(cat /proc/cpuinfo | egrep "^processor" | wc -l)
if [[ $allocated_cpus -gt 0 && $total_cpus -gt 0 ]]; then
    #disk_free=$(df -kP . 2>/dev/null | awk '{if (NR==2) print $4}')
    allocated_disk=$((100 * $allocated_cpus / $total_cpus))
    if [[ $allocated_cpus -lt 32 ]]; then
        add_config_line GLIDEIN_DISK "$allocated_disk%"
        add_condor_vars_line GLIDEIN_DISK "C" "-" "+" "N" "N" "-"
    fi
fi

set_unexported_condor_config_attribute () {
    # Sets the value of a config knob in the condor config;
    # does not export it as a startd attribute, nor does it export it to the job environment
    # Reference: https://glideinwms.fnal.gov/doc.prd/factory/custom_vars.html
    local name value
    name=$1
    value=$2
    add_config_line "$name" "$value"
    add_condor_vars_line "$name" \
        "C" `# unquoted string (i.e. HTCondor keyword or expression)` \
        "-" `# no default value` \
        "+" `# also use $name for the name of the config knob` \
        "N" `# a value is not required for this attribute` \
        "N" `# do not have the startd publish this to the collector` \
        "-" `# do not export to the user job environment`
}

# Hold jobs if they exceed allocated disk (OSPOOL-26)

# Helper macros
set_unexported_condor_config_attribute  disk_exceeded  '(JobUniverse != 13 && DiskUsage =!= UNDEFINED && DiskUsage > Disk)'
set_unexported_condor_config_attribute  hold_reason_disk_exceeded  'disk usage exceeded request_disk'

# Actual knobs. The following is the equivalent of
# use POLICY : WANT_HOLD_IF(disk_exceeded, $(HOLD_SUBCODE_disk_exceeded:104), $(hold_reason_disk_exceeded))
# since metaknobs are not supported.
set_unexported_condor_config_attribute  PREEMPT  '$(disk_exceeded) || $(PREEMPT:false)'
set_unexported_condor_config_attribute  MAXJOBRETIREMENTTIME  'ifthenelse($(disk_exceeded),-1,$(MAXJOBRETIREMENTTIME:0))'

set_unexported_condor_config_attribute  WANT_SUSPEND  '$(disk_exceeded) =!= true && $(WANT_SUSPEND:false)'

set_unexported_condor_config_attribute  WANT_HOLD  '(JobUniverse != 1 && $(disk_exceeded)) || $(WANT_HOLD:false)'
set_unexported_condor_config_attribute  WANT_HOLD_SUBCODE  'ifThenElse($(disk_exceeded), 104 , $(WANT_HOLD_SUBCODE:UNDEFINED))'
set_unexported_condor_config_attribute  WANT_HOLD_REASON  'ifThenElse($(disk_exceeded), "$(hold_reason_disk_exceeded)", $(WANT_HOLD_REASON:UNDEFINED))'

# End OSPOOL-26

###########################################################
# potential fix for SU NAT issues
add_config_line CCB_HEARTBEAT_INTERVAL "120"
add_condor_vars_line CCB_HEARTBEAT_INTERVAL "C" "-" "+" "N" "N" "-"

###########################################################
# fix for chirp problem (Edgar)
add_config_line CHIRP_DELAYED_UPDATE_PREFIX "Chirp*"
add_condor_vars_line CHIRP_DELAYED_UPDATE_PREFIX "C" "-" "+" "N" "N" "-"

###########################################################
# debugging GSI
#add_config_line MASTER_DEBUG "D_SECURITY:2"
#add_condor_vars_line MASTER_DEBUG "C" "-" "+" "N" "N" "-"
#add_config_line STARTD_DEBUG "D_SECURITY:2"
#add_condor_vars_line STARTD_DEBUG "C" "-" "+" "N" "N" "-"
#add_config_line STARTER_DEBUG "D_SECURITY:2"
#add_condor_vars_line STARTER_DEBUG "C" "-" "+" "N" "N" "-"

###########################################################
# stashcp 
STASHCP=$PWD/client/stashcp
STASHCP_DEBUG="-d"
STASHCP_TEST_FILE="osdf:///ospool/uc-shared/public/OSG-Staff/validation/test.txt"
STASH_PLUGIN=$PWD/client/stash_plugin
chmod 755 $STASHCP $STASH_PLUGIN

TIMEOUT=$(which timeout 2>/dev/null)
if [ "x$TIMEOUT" != "x" ]; then
    TIMEOUT="$TIMEOUT 120s"
fi

# The bash builtin time is no good because it pollutes
# stderr with hardcoded real, sys, and user lines.
TIME=$(which time 2>/dev/null)
if [ "x$TIME" != "x" ]; then
    # Without --quiet, newer versions of TIME(1)
    # will prepend an extra line to the output
    # if the process exits with a non-zero exit code.
    # Therefore, we use $(tail -1 stashcp-test.time)
    # below to get the runtime of stashcp.
    TIME="$TIME --output=stashcp-test.time --format=%e"
fi

glidein_site=`grep -i "^GLIDEIN_Site " $glidein_config | awk '{print $2}'`
if [[ -z $OSG_SITE_NAME ]]; then
    OSG_SITE_NAME=$glidein_site
fi

# also run a simple test (TODO: make this IGWN-specific)
info "Testing $STASHCP $STASHCP_DEBUG $STASHCP_TEST_FILE..."
if $TIME $TIMEOUT $STASHCP $STASHCP_DEBUG $STASHCP_TEST_FILE stashcp-test.file >> stashcp-test.log 2>&1; then
    if [ -f stashcp-test.time ]; then
        info "Succeeded (in $(tail -1 stashcp-test.time)s)!"
    else
        info "Succeeded!"
    fi
    add_config_line FILETRANSFER_PLUGINS "\$(FILETRANSFER_PLUGINS),$STASH_PLUGIN"
    add_condor_vars_line FILETRANSFER_PLUGINS "C" "-" "+" "N" "N" "-"
else
    if [ "$?" -eq "124" ]; then
        warn "Failed (timed out after 120s)! stashcp output:"
    elif [ -f stashcp-test.time ]; then
        warn "Failed (in $(tail -1 stashcp-test.time)s)! stashcp output:"
    else
        warn "Failed! stashcp output:"
    fi
    while read line; do warn "$line"; done < stashcp-test.log
fi

##################################################################
# Generate a minimal `STARTER_JOB_ENVIRONMENT`, mostly composed of
# informational variables that are considered safe to always leak to
# the job environment.
#
# Source of OSG_* variables:
#   https://github.com/opensciencegrid/osg-configure/blob/dcd02313500cf113e8a6c27571197b4803295774/scripts/osg-configure#L27
# Removed the following ones that don't appear actively used anymore:
#  OSG_GRID, OSG_APP, OSG_DATA, OSG_SITE_READ, OSG_SITE_WRITE
# Removed $OSG_WN_TMP because any job should use the HTCondor-provided scratch dir.
# Considered and not passed through:
#   LANG
info "Calculating default job environment variables."

job_env=
for envvar in \
     OSG_SITE_NAME \
     OSG_HOSTNAME \
     OSG_SQUID_LOCATION \
     http_proxy \
     https_proxy \
     FTP_PROXY \
     X509_USER_PROXY \
; do

if [ ! -z ${!envvar+x} ]; then
  add_config_line "${envvar}" "${!envvar}"
  add_condor_vars_line "${envvar}" "C" "-" "${envvar}" "N" "N" "+"
fi

done
###########################################################

echo "All done (osgvo-additional-htcondor-config)"

